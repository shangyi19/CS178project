{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn import *\n",
    "\n",
    "from itertools import product\n",
    "# from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data into Dataframe for Stacking \n",
    "# Load the training data\n",
    "df_X = pd.read_table('data/X_train.txt', delim_whitespace=True, names=None,header=None)\n",
    "df_Y = pd.read_table('data/Y_train.txt', delim_whitespace=True, names=None,header=None)\n",
    "\n",
    "# And the test features\n",
    "df_Xte = pd.read_table('data/X_test.txt', delim_whitespace=True, names=None,header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check length of test data\n",
    "df_Xte.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>240.92</td>\n",
       "      <td>232.44</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.26710</td>\n",
       "      <td>6.4128</td>\n",
       "      <td>1.98690</td>\n",
       "      <td>3.9756</td>\n",
       "      <td>2.3392</td>\n",
       "      <td>6.3537</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>249.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>242.31</td>\n",
       "      <td>233.68</td>\n",
       "      <td>1579.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.68310</td>\n",
       "      <td>6.0824</td>\n",
       "      <td>1.19640</td>\n",
       "      <td>3.4577</td>\n",
       "      <td>2.0416</td>\n",
       "      <td>7.6746</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>223.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>227.64</td>\n",
       "      <td>204.42</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>603.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>1.52860</td>\n",
       "      <td>17.8690</td>\n",
       "      <td>13.23000</td>\n",
       "      <td>5.7120</td>\n",
       "      <td>4.7216</td>\n",
       "      <td>6.6030</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>234.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>236.27</td>\n",
       "      <td>229.73</td>\n",
       "      <td>7716.0</td>\n",
       "      <td>3907.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.60465</td>\n",
       "      <td>8.0497</td>\n",
       "      <td>3.44760</td>\n",
       "      <td>2.4845</td>\n",
       "      <td>1.5741</td>\n",
       "      <td>1.4205</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>234.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>245.51</td>\n",
       "      <td>234.10</td>\n",
       "      <td>545.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.74730</td>\n",
       "      <td>5.2649</td>\n",
       "      <td>0.86766</td>\n",
       "      <td>5.9626</td>\n",
       "      <td>4.2450</td>\n",
       "      <td>3.1429</td>\n",
       "      <td>24.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1       2       3       4       5      6        7        8   \\\n",
       "0  242.0  227.0  240.92  232.44  1195.0   253.0    0.0  1.26710   6.4128   \n",
       "1  249.0  230.0  242.31  233.68  1579.0   243.0    0.0  9.68310   6.0824   \n",
       "2  223.0  195.0  227.64  204.42  1034.0   603.0  318.0  1.52860  17.8690   \n",
       "3  234.0  221.0  236.27  229.73  7716.0  3907.0    0.0  0.60465   8.0497   \n",
       "4  234.0  233.0  245.51  234.10   545.0    21.0    0.0  6.74730   5.2649   \n",
       "\n",
       "         9       10      11      12    13  \n",
       "0   1.98690  3.9756  2.3392  6.3537   0.0  \n",
       "1   1.19640  3.4577  2.0416  7.6746   0.0  \n",
       "2  13.23000  5.7120  4.7216  6.6030   0.0  \n",
       "3   3.44760  2.4845  1.5741  1.4205   0.0  \n",
       "4   0.86766  5.9626  4.2450  3.1429  24.2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if data has been loaded correctly \n",
    "df_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  1\n",
       "2  1\n",
       "3  1\n",
       "4  0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if data has been loaded correctly \n",
    "df_Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>246.00</td>\n",
       "      <td>226.0</td>\n",
       "      <td>243.27</td>\n",
       "      <td>233.43</td>\n",
       "      <td>7121.0</td>\n",
       "      <td>648.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1235</td>\n",
       "      <td>5.5226</td>\n",
       "      <td>1.9747</td>\n",
       "      <td>2.3390</td>\n",
       "      <td>1.1438</td>\n",
       "      <td>5.3022</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>239.00</td>\n",
       "      <td>226.0</td>\n",
       "      <td>240.77</td>\n",
       "      <td>233.31</td>\n",
       "      <td>2109.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.7154</td>\n",
       "      <td>6.3213</td>\n",
       "      <td>1.5999</td>\n",
       "      <td>4.3318</td>\n",
       "      <td>3.1834</td>\n",
       "      <td>3.0579</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>251.62</td>\n",
       "      <td>232.0</td>\n",
       "      <td>245.82</td>\n",
       "      <td>233.57</td>\n",
       "      <td>199.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4131</td>\n",
       "      <td>5.7395</td>\n",
       "      <td>1.2936</td>\n",
       "      <td>5.6142</td>\n",
       "      <td>2.0601</td>\n",
       "      <td>20.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>253.00</td>\n",
       "      <td>243.0</td>\n",
       "      <td>249.18</td>\n",
       "      <td>249.18</td>\n",
       "      <td>4095.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.3200</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.5908</td>\n",
       "      <td>1.2399</td>\n",
       "      <td>20.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>247.00</td>\n",
       "      <td>240.0</td>\n",
       "      <td>248.12</td>\n",
       "      <td>248.12</td>\n",
       "      <td>321.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.8170</td>\n",
       "      <td>3.4157</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.2366</td>\n",
       "      <td>1.2236</td>\n",
       "      <td>20.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1       2       3       4      5    6        7       8       9   \\\n",
       "0  246.00  226.0  243.27  233.43  7121.0  648.0  0.0   1.1235  5.5226  1.9747   \n",
       "1  239.00  226.0  240.77  233.31  2109.0  560.0  0.0   5.7154  6.3213  1.5999   \n",
       "2  251.62  232.0  245.82  233.57   199.0   14.0  0.0   3.4131  5.7395  1.2936   \n",
       "3  253.00  243.0  249.18  249.18  4095.0    0.0  0.0  10.3200  2.5050  0.0000   \n",
       "4  247.00  240.0  248.12  248.12   321.0    0.0  0.0  10.8170  3.4157  0.0000   \n",
       "\n",
       "       10      11       12   13  \n",
       "0  2.3390  1.1438   5.3022  0.0  \n",
       "1  4.3318  3.1834   3.0579  0.0  \n",
       "2  5.6142  2.0601  20.0000  0.0  \n",
       "3  1.5908  1.2399  20.0000  0.0  \n",
       "4  4.2366  1.2236  20.0000  0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check Test data load\n",
    "df_Xte.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data in the form of arrays to perform individual Model training & testing\n",
    "# Load the training data\n",
    "X = np.genfromtxt('data/X_train.txt', delimiter=None)\n",
    "Y = np.genfromtxt('data/Y_train.txt', delimiter=None)\n",
    "\n",
    "# And the test features\n",
    "Xte = np.genfromtxt('data/X_test.txt', delimiter=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 14) (200000,) (200000, 14)\n"
     ]
    }
   ],
   "source": [
    "#Check Shape\n",
    "print(X.shape, Y.shape, Xte.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[246.    , 226.    , 243.27  , ...,   1.1438,   5.3022,   0.    ],\n",
       "       [239.    , 226.    , 240.77  , ...,   3.1834,   3.0579,   0.    ],\n",
       "       [251.62  , 232.    , 245.82  , ...,   2.0601,  20.    ,   0.    ],\n",
       "       ...,\n",
       "       [252.    , 237.    , 248.23  , ...,   1.8303,  20.    ,   0.    ],\n",
       "       [247.    , 235.    , 247.1   , ...,   2.1439,  20.    ,   0.    ],\n",
       "       [247.    , 238.    , 248.61  , ...,   1.5008,  20.    ,   0.    ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check loaded test data\n",
    "Xte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[242.    , 227.    , 240.92  , ...,   2.3392,   6.3537,   0.    ],\n",
       "       [249.    , 230.    , 242.31  , ...,   2.0416,   7.6746,   0.    ],\n",
       "       [223.    , 195.    , 227.64  , ...,   4.7216,   6.603 ,   0.    ],\n",
       "       ...,\n",
       "       [250.    , 234.    , 244.51  , ...,   3.3698,  20.    ,   0.    ],\n",
       "       [236.5   , 227.    , 241.98  , ...,   2.7834,   2.5209,   0.    ],\n",
       "       [242.    , 229.    , 241.38  , ...,   1.9358,   2.1394,   0.    ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check X data\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 0., 0., 1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check Y data\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split Array data training / validation data for individual model training\n",
    "x_train, x_validation, y_train, y_validation = model_selection.train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions STARTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to save Individual Model Test Probabilities for Submission to Kaggle\n",
    "def SavetoTextFile(model_name,probs,Xte):\n",
    "    # Create the data for submission by taking the P(Y=1) column from probs and just add a running index as the first column.\n",
    "    Y_sub = np.vstack([np.arange(Xte.shape[0]), probs[:, 1]]).T\n",
    "    # We specify the header (ID, Prob1) and also specify the comments as '' so the header won't be commented out with\n",
    "    # the sign.\n",
    "    file_name='Solutions/Y_sub_'+model_name+'.txt'\n",
    "    np.savetxt(file_name, Y_sub, '%d, %.5f', header='ID,Prob1', comments='', delimiter=',')\n",
    "    print('{} Saved'.format(file_name))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_calculate_print(x,y,classifier):\n",
    "    roc = metrics.roc_auc_score(y,classifier.predict_proba(x)[:,1])\n",
    "    return(roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions ENDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest STARTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper Paramters of Random Forest:\n",
    "\n",
    "- n_estimators --> No of trees\n",
    "- criterion --> entropy or gini\n",
    "- max_features --> Use Sub set of list of features\n",
    "- bootstrap--> True by default\n",
    "- oob_score --> default = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random orest training started\n",
      "Random Forest training finished, took 75.52354693412781 seconds\n",
      "Validation AUC: 0.7598094409091216\n",
      "Train AUC: 0.9914036951932823\n"
     ]
    }
   ],
   "source": [
    "#Execute this\n",
    "\n",
    "rfc=RandomForestClassifier(n_estimators=65, criterion = 'entropy', random_state = 0,n_jobs=-1, oob_score=True)\n",
    "\n",
    "print(\"Random Forest training started\")\n",
    "\n",
    "starting_time = time.time()\n",
    "\n",
    "rfc.fit(x_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Random Forest training finished, took {} seconds\".format(end_time - starting_time))\n",
    "\n",
    "print('Validation AUC: {}'.format(metrics.roc_auc_score(y_validation, rfc.predict_proba(x_validation)[:,1])))\n",
    "\n",
    "print('Train AUC: {}'.format(metrics.roc_auc_score(y_train, rfc.predict_proba(x_train)[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         1.        ]\n",
      " [0.50923077 0.49076923]\n",
      " [0.75692308 0.24307692]\n",
      " [0.96879121 0.03120879]\n",
      " [0.84615385 0.15384615]]\n"
     ]
    }
   ],
   "source": [
    "#Getting the individual Probabilities\n",
    "#This is what needs to be converted to txt for submission\n",
    "\n",
    "rfc_probs = rfc.predict_proba(Xte)\n",
    "print(rfc_probs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000 200000\n"
     ]
    }
   ],
   "source": [
    "#Check if no. of rows of predicted probabilites & Xtest match\n",
    "print(Xte.shape[0],rfc_probs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solutions/Y_sub_rfc.txt Saved\n"
     ]
    }
   ],
   "source": [
    "# Make the prediction probabilities text file for Submission to Kaggle\n",
    "SavetoTextFile('rfc',rfc_probs,Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB Score: 0.72418125\n",
      "Score: 0.72515 \n"
     ]
    }
   ],
   "source": [
    "#Out of Bag Score\n",
    "#Only relevent to Random Forest\n",
    "print('OOB Score: {}'.format(rfc.oob_score_))\n",
    "print('Score: {} '.format(rfc.score(x_validation, y_validation)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Random Forest Hyper Parameter Optimization ***\n",
    "\n",
    "RandomForest Classifier Choosing the Optimial model\n",
    "- n_estimators=65, criterion = 'entropy',n_jobs=-1, oob_score=True  - 0.7598 Validation AUC, .9914 Train AUC - 47 secs\n",
    "- n_estimators=150, criterion = 'entropy',n_jobs=-1, oob_score=True - 0.7609 Validation AUC, .9918 Train AUC - 112 secs\n",
    "- n_estimators=200, criterion = 'entropy',n_jobs=-1, oob_score=True - 0.7613 Validation AUC, .9919 Train AUC - 168 secs\n",
    "- n_estimators=400, criterion = 'entropy',n_jobs=-1, oob_score=True - 0.7615 Validation AUC, .9919 Train AUC - 371 secs\n",
    "\n",
    "No Significant change in Validation accuracy with increase in no. of trees so changing criterion & trying\n",
    "\n",
    "- n_estimators=400, criterion = 'gini',n_jobs=-1, oob_score=True - 0.7605 Validation AUC, .9920 Train AUC - 371 secs\n",
    "\n",
    "No Significant change in Validation accuracy with change in Criterion = Gini\n",
    "Setting oob_score=False & Trying\n",
    "\n",
    "- n_estimators=400, criterion = 'gini',n_jobs=-1, oob_score=False - 0.7605 Validation AUC, .9920 Train AUC - 215 secs\n",
    "\n",
    "\n",
    "*** Conclusion: ***\n",
    "\n",
    "From the above results we choose the below as our optimal Hyper parameters:\n",
    "\n",
    "- n_estimators=65,criterion = 'entropy',n_jobs=-1, oob_score=True\n",
    "- The above gives us a Validation AUC of 0.7598 & takes only 47 seconds to train\n",
    "- Criterion : Gini & Entroy : These usually yield similar results so we can choose either one, although Gini is a little Faster\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random FOrest ENDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes STARTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes training started\n",
      "Naive Bayes training finished, took 0.22266769409179688 seconds\n",
      "Naive Bayes Validation AUC: 0.6124095289184106\n",
      "Naive Bayes Train AUC: 0.6124943821019428\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_classifier = GaussianNB()\n",
    "\n",
    "print(\"Naive Bayes training started\")\n",
    "\n",
    "starting_time = time.time()\n",
    "\n",
    "naive_bayes_classifier.fit(x_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Naive Bayes training finished, took {} seconds\".format(end_time - starting_time))\n",
    "\n",
    "#Validation AUC Calculation\n",
    "\n",
    "#Since roc_auc_score needs probabilies as input we r using .predict_proba\n",
    "naive_bayes_classifier_roc_validation = metrics.roc_auc_score(\n",
    "    y_validation, naive_bayes_classifier.predict_proba(x_validation)[:,1])\n",
    "\n",
    "print('Naive Bayes Validation AUC: {}'.format(naive_bayes_classifier_roc_validation))\n",
    "\n",
    "#Training AUC Calculation\n",
    "naive_bayes_classifier_roc_train = metrics.roc_auc_score(\n",
    "   y_train, naive_bayes_classifier.predict_proba(x_train)[:,1])\n",
    "print('Naive Bayes Train AUC: {}'.format(naive_bayes_classifier_roc_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.59620622 0.40379378]\n",
      " [0.57795356 0.42204644]\n",
      " [0.80870104 0.19129896]\n",
      " [0.98150997 0.01849003]\n",
      " [0.97542329 0.02457671]]\n"
     ]
    }
   ],
   "source": [
    "#Getting the individual Probabilities\n",
    "#This is what needs to be converted to txt for submission\n",
    "\n",
    "naive_bayes_classifier_probs = naive_bayes_classifier.predict_proba(Xte)\n",
    "print(naive_bayes_classifier_probs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solutions/Y_sub_naive_bayes.txt Saved\n"
     ]
    }
   ],
   "source": [
    "# Make the prediction probabilities text file for Submission to Kaggle\n",
    "SavetoTextFile('naive_bayes',naive_bayes_classifier_probs,Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Checking scores\n",
    "#For reference only\n",
    "y_pred = naive_bayes_classifier.predict(x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17409  8882]\n",
      " [ 6655  7054]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.611575"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cross Checking scores\n",
    "#For reference only\n",
    "cm = confusion_matrix(y_validation,y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_validation,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes ENDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree STARTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree training started\n",
      "Decision Tree training finished, took 5.874881029129028 seconds\n",
      "Decision Tree Validation AUC: 0.6599961391510298\n",
      "Decision Tree Train AUC: 0.9937726770838594\n"
     ]
    }
   ],
   "source": [
    "#Execute\n",
    "decision_tree_classifier = tree.DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "print(\"Decision Tree training started\")\n",
    "\n",
    "starting_time = time.time()\n",
    "\n",
    "decision_tree_classifier.fit(x_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Decision Tree training finished, took {} seconds\".format(end_time - starting_time))\n",
    "\n",
    "#Validation AUC Calculation\n",
    "\n",
    "decision_tree_classifier_validation_roc = auc_calculate_print(x_validation,y_validation,decision_tree_classifier)\n",
    "\n",
    "print('Decision Tree Validation AUC: {}'.format(decision_tree_classifier_validation_roc))\n",
    "\n",
    "#Training AUC Calculation\n",
    "\n",
    "decision_tree_classifier_train_roc= auc_calculate_print(x_train,y_train,decision_tree_classifier)\n",
    "\n",
    "print('Decision Tree Train AUC: {}'.format(decision_tree_classifier_train_roc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Getting the individual Probabilities\n",
    "#This is what needs to be converted to txt for submission\n",
    "\n",
    "decision_tree_classifier_probs = decision_tree_classifier.predict_proba(Xte)\n",
    "print(decision_tree_classifier_probs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solutions/Y_sub_decision_tree.txt Saved\n"
     ]
    }
   ],
   "source": [
    "# Make the prediction probabilities text file for Submission to Kaggle\n",
    "SavetoTextFile('decision_tree',decision_tree_classifier_probs,Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Checking scores\n",
    "#For reference only\n",
    "y_pred = decision_tree_classifier.predict(x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20363  5928]\n",
      " [ 6658  7051]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.68535"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cross Checking scores\n",
    "#For reference only\n",
    "cm = confusion_matrix(y_validation,y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_validation,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree ENDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost STARTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning_ratefloat, default=1.\n",
    "- Learning rate shrinks the contribution of each classifier by learning_rate. There is a trade-off between learning_rate and n_estimators.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ada Boost training started\n",
      "Ada Boost training finished, took 915.8517315387726 seconds\n",
      "Ada Boost Validation AUC: 0.6599961391510298\n",
      "Ada Boost Train AUC: 0.9937726770838594\n"
     ]
    }
   ],
   "source": [
    "ada_boost_classifier = AdaBoostClassifier(tree.DecisionTreeClassifier(random_state=0),\n",
    "                                          algorithm='SAMME.R',n_estimators=200, learning_rate=0.5)\n",
    "\n",
    "print(\"Ada Boost training started\")\n",
    "\n",
    "starting_time = time.time()\n",
    "\n",
    "ada_boost_classifier.fit(x_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Ada Boost training finished, took {} seconds\".format(end_time - starting_time))\n",
    "\n",
    "#Validation AUC Calculation\n",
    "\n",
    "ada_boost_classifier_validation_roc = auc_calculate_print(x_validation,y_validation,ada_boost_classifier)\n",
    "\n",
    "print('Ada Boost Validation AUC: {}'.format(ada_boost_classifier_validation_roc))\n",
    "\n",
    "#Training AUC Calculation\n",
    "\n",
    "ada_boost_classifier_train_roc= auc_calculate_print(x_train,y_train,ada_boost_classifier)\n",
    "\n",
    "print('Ada Boost Train AUC: {}'.format(ada_boost_classifier_train_roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.11943906e-03 9.96880561e-01]\n",
      " [1.56564617e-01 8.43435383e-01]\n",
      " [9.84272850e-01 1.57271498e-02]\n",
      " [9.99869853e-01 1.30146850e-04]\n",
      " [9.99409280e-01 5.90720119e-04]]\n"
     ]
    }
   ],
   "source": [
    "#Getting the individual Probabilities\n",
    "#This is what needs to be converted to txt for submission\n",
    "\n",
    "ada_boost_classifier_probs = ada_boost_classifier.predict_proba(Xte)\n",
    "print(ada_boost_classifier_probs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solutions/Y_sub_ada_boost.txt Saved\n"
     ]
    }
   ],
   "source": [
    "# Make the prediction probabilities text file for Submission to Kaggle\n",
    "SavetoTextFile('ada_boost',ada_boost_classifier_probs,Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Checking scores\n",
    "#For reference only\n",
    "y_pred = ada_boost_classifier.predict(x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21354  4937]\n",
      " [ 6138  7571]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.723125"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cross Checking scores\n",
    "#For reference only\n",
    "cm = confusion_matrix(y_validation,y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_validation,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Ada Boost Hyper Parameter Optimization ***\n",
    "\n",
    "*** n_estimators: ***\n",
    "\n",
    "- DecisionTreeClassifier(random_state=0),algorithm='SAMME.R',n_estimators=100, learning_rate=0.5  - 0.7277 Validation AUC,  .9937 Train AUC\n",
    "- DecisionTreeClassifier(random_state=0),algorithm='SAMME.R',n_estimators=200, learning_rate=0.5  - 0.7374 Validation AUC,  .9937 Train AUC - 489 Secs\n",
    "- DecisionTreeClassifier(random_state=0),algorithm='SAMME.R',n_estimators=500, learning_rate=0.5  - 0.7476 Validation AUC,  .9937 Train AUC - 1067 Secs\n",
    "\n",
    "Since, the Validation AUC is not improving substantially .7274 (n_estimators=200) Vs 0.7476 (n_estimators=500) we change the learning rate to 0.7 & n_estimators=200\n",
    "\n",
    "*** learning_rate: ***\n",
    "\n",
    "- DecisionTreeClassifier(random_state=0),algorithm='SAMME.R',n_estimators=500, learning_rate=0.7  - 0.7390 Validation AUC,  .9937 Train AUC - 1067 Secs\n",
    "\n",
    "Since, learning rate = 0.7 caused a drop in the AUC accuracy from .7476 (learning_rate=0.5) to  0.7390 (learning_rate=0.7) we decrease the learning rate to 0.6 & check the results\n",
    "\n",
    "- DecisionTreeClassifier(random_state=0),algorithm='SAMME.R',n_estimators=200, learning_rate=0.6  - 0.7387 Validation AUC,  .9937 Train AUC - 459 Secs\n",
    "- DecisionTreeClassifier(random_state=0),algorithm='SAMME.R',n_estimators=500, learning_rate=0.6  - 0.7478 Validation AUC,  .9937 Train AUC - 1017 Secs\n",
    "\n",
    "*** Conclusion: ***\n",
    "\n",
    "From the data above its clear that higher number of n_estimators or Trees is not making much of a impact on the Validation AUC, hence we will choose:\n",
    "- n_estimators=200, learning_rate=0.5 \n",
    "- as its provides the optimum Validation AUC of .7374 in less amount of training time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost ENDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier STARTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss{‘deviance’, ‘exponential’}, default=’deviance’\n",
    "- loss function to be optimized. ‘deviance’ refers to deviance (= logistic regression) for classification with probabilistic outputs. For loss ‘exponential’ gradient boosting recovers the AdaBoost algorithm.\n",
    "\n",
    "learning_ratefloat, default=0.1\n",
    "- learning rate shrinks the contribution of each tree by learning_rate. There is a trade-off between learning_rate and n_estimators.\n",
    "\n",
    "n_estimatorsint, default=100\n",
    "- The number of boosting stages to perform. Gradient boosting is fairly robust to over-fitting so a large number usually results in better performance.\n",
    "\n",
    "max_depth int, default=3\n",
    "- maximum depth of the individual regression estimators. The maximum depth limits the number of nodes in the tree. Tune this parameter for best performance; the best value depends on the interaction of the input variables.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting training started\n",
      "Gradient Boosting training finished, took 396.37238597869873 seconds\n",
      "Validation AUC: 0.7720651462620819\n",
      "Train AUC: 0.8455202295730051\n"
     ]
    }
   ],
   "source": [
    "gradient_boosting_classifier = GradientBoostingClassifier(n_estimators=500, learning_rate=0.5,\n",
    "     max_depth=4, max_leaf_nodes=15, random_state=0)\n",
    "\n",
    "print(\"Gradient Boosting training started\")\n",
    "\n",
    "starting_time = time.time()\n",
    "\n",
    "gradient_boosting_classifier.fit(x_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Gradient Boosting training finished, took {} seconds\".format(end_time - starting_time))\n",
    "\n",
    "#Validation AUC Calculation\n",
    "\n",
    "gradient_boosting_classifier_roc_validation = auc_calculate_print(x_validation,y_validation,gradient_boosting_classifier)\n",
    "\n",
    "\n",
    "print('Validation AUC: {}'.format(gradient_boosting_classifier_roc_validation))\n",
    "\n",
    "#Training AUC Calculation\n",
    "\n",
    "gradient_boosting_classifier_roc_train= auc_calculate_print(x_train,y_train,gradient_boosting_classifier)\n",
    "\n",
    "\n",
    "print('Train AUC: {}'.format(gradient_boosting_classifier_roc_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.19771194 0.80228806]\n",
      " [0.44725613 0.55274387]\n",
      " [0.80402908 0.19597092]\n",
      " [0.96567519 0.03432481]\n",
      " [0.90796277 0.09203723]]\n"
     ]
    }
   ],
   "source": [
    "#Getting the individual Probabilities\n",
    "#This is what needs to be converted to txt for submission\n",
    "\n",
    "gradient_boosting_classifier_probs = gradient_boosting_classifier.predict_proba(Xte)\n",
    "print(gradient_boosting_classifier_probs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solutions/Y_sub_gradient_boosting.txt Saved\n"
     ]
    }
   ],
   "source": [
    "# Make the prediction probabilities text file for Submission to Kaggle\n",
    "SavetoTextFile('gradient_boosting',gradient_boosting_classifier_probs,Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Checking scores\n",
    "#For reference only\n",
    "y_pred = gradient_boosting_classifier.predict(x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23284  3007]\n",
      " [ 7446  6263]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.738675"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cross Checking scores\n",
    "#For reference only\n",
    "cm = confusion_matrix(y_validation,y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_validation,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Gradient Boosting Hyper Parameter Optimization ***\n",
    "\n",
    "\n",
    "Gradient Boosting AUC At different Hyper parameters:\n",
    "\n",
    "*** n_estimators: ***\n",
    "\n",
    "- n_estimators=100, learning_rate=0.5,max_depth=10, max_leaf_nodes=15  - .74   Validation AUC,  .7708 \n",
    "- n_estimators=200, learning_rate=0.5,max_depth=10, max_leaf_nodes=15  - .75   Validation AUC , .8059   Train AUC\n",
    "- n_estimators=300, learning_rate=0.5,max_depth=10, max_leaf_nodes=15  - .7641 Validation AUC , .0.8294 Train AUC - 446 secs\n",
    "- n_estimators=500, learning_rate=0.5,max_depth=10, max_leaf_nodes=15  - .7714 Validation AUC , .0.8620 Train AUC - 499 secs\n",
    "\n",
    "*** learning_rate: ***\n",
    "\n",
    "Changing Learning Rate = 0.1:\n",
    "- n_estimators=100, learning_rate=0.1,max_depth=10, max_leaf_nodes=15  - .7194 Validation AUC , 0.7244 Train AUC - 145 secs\n",
    "- n_estimators=200, learning_rate=0.1,max_depth=10, max_leaf_nodes=15  - .7321 Validation AUC , 0.7458 Train AUC - 233 secs\n",
    "- n_estimators=400, learning_rate=0.1,max_depth=10, max_leaf_nodes=15  - .7474 Validation AUC , 0.7740 Train AUC - 445 secs\n",
    "\n",
    "Changing Learning Rate = 0.2:\n",
    "- n_estimators=400, learning_rate=0.2,max_depth=10, max_leaf_nodes=15  - .7631 Validation AUC , 0.8065 Train AUC - 513 secs\n",
    "\n",
    "So, we conclude that the 0.5 learning rate seems to be the best one as its givng us .7714 Validation Accuracy with 500 estimatiors. Now checking by changing dept\n",
    "\n",
    "*** max_depth: ***\n",
    "\n",
    "- n_estimators=500, learning_rate=0.5, max_depth=5, max_leaf_nodes=15 - .7746 Validation AUC , 0.8550 Train AUC - 456 secs\n",
    "- n_estimators=500, learning_rate=0.5, max_depth=7, max_leaf_nodes=15 - .7731 Validation AUC , 0.8598 Train AUC - 456 secs\n",
    "- n_estimators=500, learning_rate=0.5, max_depth=4, max_leaf_nodes=15 - .7720 Validation AUC , 0.8455 Train AUC - 456 secs\n",
    "- n_estimators=500, learning_rate=0.5, max_depth=3, max_leaf_nodes=15 - .7545 Validation AUC , 0.8455 Train AUC - 277 secs\n",
    "\n",
    "*** Conclusion: ***\n",
    "\n",
    "From the Above Hyper-parameter Tuning data we conclude that:\n",
    "\n",
    "- n_estimators=500, learning_rate=0.5, max_depth=4, max_leaf_nodes=15 \n",
    "- .7720 Validation AUC , 0.8455 Train AUC - 456 secs\n",
    "- The above seems to be optimal as increasing the depth does not significantly improve the Validation AUC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier ENDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking STARTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Dataframe's for data\n",
    "# split training / validation data\n",
    "X_train,X_validation,Y_train,Y_validation=model_selection.train_test_split(df_X,df_Y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160000, 14) (40000, 14) (160000, 1) (40000, 1)\n"
     ]
    }
   ],
   "source": [
    "#Checking Shape\n",
    "print(X_train.shape,X_validation.shape,Y_train.shape,Y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stacking(model,train,y,test,n_fold):\n",
    "    folds=StratifiedKFold(n_splits=n_fold,random_state=1)\n",
    "    test_pred=np.empty((0,1),float)\n",
    "    train_pred=np.empty((0,1),float)\n",
    "    \n",
    "    for train_indices,val_indices in folds.split(train,y):\n",
    "        x_train,x_val=train.iloc[train_indices,:],train.iloc[val_indices,:]\n",
    "        y_train,y_val=y.iloc[train_indices],y.iloc[val_indices]\n",
    "        model.fit(X=x_train,y=y_train)\n",
    "        train_pred=np.append(train_pred,model.predict(x_val))\n",
    "    test_pred=model.predict(test)\n",
    "    \n",
    "    return test_pred.reshape(-1,1),train_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking For Validation Data STARTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Stacking training started\n",
      "Random Forest Stacking training finished, took 487.4433162212372 seconds\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Stacking Model \n",
    "\n",
    "#For X Validation Data to check model performace\n",
    "\n",
    "rfc_model1 = RandomForestClassifier(n_estimators=65, criterion = 'entropy', random_state = 0,n_jobs=-1, oob_score=True)\n",
    "\n",
    "print(\"Random Forest Stacking training started\")\n",
    "\n",
    "starting_time = time.time()\n",
    "\n",
    "test_X_validation_pred1 ,train_X_validation_pred1=Stacking(model=rfc_model1,n_fold=10, train=X_train,test=X_validation,y=Y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Random Forest Stacking training finished, took {} seconds\".format(end_time - starting_time))\n",
    "\n",
    "\n",
    "train_X_validation_pred1=pd.DataFrame(train_X_validation_pred1)\n",
    "test_X_validation_pred1=pd.DataFrame(test_X_validation_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ada Boost Stacking training started\n",
      "Ada Boost Stacking training finished, took 7819.5468628406525 seconds\n"
     ]
    }
   ],
   "source": [
    "#Ada Boost Stacking Model 2 \n",
    "#For X Validation Data to check model performace\n",
    "\n",
    "ada_boost_model2 =AdaBoostClassifier(tree.DecisionTreeClassifier(random_state=0),algorithm='SAMME.R',\n",
    "                                     n_estimators=200, learning_rate=0.5)\n",
    "\n",
    "print(\"Ada Boost Stacking training started\")\n",
    "\n",
    "starting_time = time.time()\n",
    "\n",
    "test_X_validation_pred2 ,train_X_validation_pred2=Stacking(model=ada_boost_model2,n_fold=10, \n",
    "                                                           train=X_train,test=X_validation,y=Y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Ada Boost Stacking training finished, took {} seconds\".format(end_time - starting_time))\n",
    "\n",
    "train_X_validation_pred2=pd.DataFrame(train_X_validation_pred2)\n",
    "\n",
    "test_X_validation_pred2=pd.DataFrame(test_X_validation_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Stacking training started (Validation Data)\n",
      "Gradient Boosting Stacking training finished, took 2597.1103184223175 seconds\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting Stacking Model 3\n",
    "#For X Validation Data to check model performace\n",
    "\n",
    "gradient_boost_model3 =gradient_boosting_classifier = GradientBoostingClassifier(n_estimators=500, learning_rate=0.5,\n",
    "     max_depth=4, max_leaf_nodes=15, random_state=0)\n",
    "\n",
    "print(\"Gradient Boosting Stacking training started (Validation Data)\")\n",
    "\n",
    "starting_time = time.time()\n",
    "\n",
    "#XValidation data\n",
    "test_X_validation_pred3 ,train_X_validation_pred3=Stacking(model=gradient_boost_model3,n_fold=10, train=X_train,\n",
    "                                                           test=X_validation,y=Y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Gradient Boosting Stacking training finished, took {} seconds\".format(end_time - starting_time))\n",
    "\n",
    "train_X_validation_pred3=pd.DataFrame(train_X_validation_pred3)\n",
    "\n",
    "test_X_validation_pred3=pd.DataFrame(test_X_validation_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining All 3 Models Random Forest, AdaBoost, Gradient Boosting STARTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.737075"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For X_Validation Data\n",
    "\n",
    "validation_prediction = pd.concat([train_X_validation_pred1, train_X_validation_pred2,train_X_validation_pred3], axis=1)\n",
    "\n",
    "test_prediction = pd.concat([test_X_validation_pred1, test_X_validation_pred2, test_X_validation_pred3], axis=1)\n",
    "\n",
    "model = LogisticRegression(random_state=1)\n",
    "\n",
    "#Fitting model on Train Data\n",
    "model.fit(validation_prediction,Y_train)\n",
    "\n",
    "#Calculating Score on Test Prediction & Y_validation(this is our true test data for validation)\n",
    "\n",
    "model.score(test_prediction, Y_validation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the individual Probabilities\n",
    "\n",
    "probs = model.predict_proba(test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Logistic Regression Validation AUC: 0.7266510009026358\n",
      "Stacked Logistic Regression Train AUC: 0.7249642711096788\n"
     ]
    }
   ],
   "source": [
    "#Execute for X_Validation ONLY\n",
    "#ROC / AUC Score\n",
    "\n",
    "# Stacking_LogisticRegression_classifier_roc = metrics.roc_auc_score(\n",
    "#     Y_validation, model.predict_proba(test_prediction)[:,1])\n",
    "\n",
    "Stacking_LogisticRegression_classifier_roc_validation = auc_calculate_print(test_prediction,Y_validation,model)\n",
    "\n",
    "\n",
    "print('Stacked Logistic Regression Validation AUC: {}'.format(Stacking_LogisticRegression_classifier_roc_validation))\n",
    "\n",
    "#Training AUC Calculation\n",
    "\n",
    "# Stacking_LogisticRegression_classifier_roc_train = metrics.roc_auc_score(\n",
    "#     Y_train, model.predict_proba(validation_prediction)[:,1])\n",
    "\n",
    "Stacking_LogisticRegression_classifier_roc_train = auc_calculate_print(validation_prediction,Y_train,model)\n",
    "\n",
    "print('Stacked Logistic Regression Train AUC: {}'.format(Stacking_LogisticRegression_classifier_roc_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining All 3 Models Random Forest, AdaBoost, Gradient Boosting ENDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking For Validation Data ENDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking For Xte(Kaggle Submission) Data STARTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Model 1\n",
    "#Kaggle Test data\n",
    "\n",
    "rfc_model1 = RandomForestClassifier(n_estimators=65, criterion = 'entropy', random_state = 0,n_jobs=-1, oob_score=True)\n",
    "\n",
    "print(\"Random Forest Kaggle Test Data training started\")\n",
    "starting_time = time.time()\n",
    "\n",
    "test_pred1 ,train_pred1=Stacking(model=rfc_model1,n_fold=10, train=X_train,test=df_Xte,y=Y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Random Forest Kaggle Test Data training finished, took {} seconds\".format(end_time - starting_time))\n",
    "\n",
    "train_pred1=pd.DataFrame(train_pred1)\n",
    "test_pred1=pd.DataFrame(test_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ada Boost Model 2\n",
    "#Use this KAGGLE Test dataset\n",
    "\n",
    "ada_boost_model2 =AdaBoostClassifier(tree.DecisionTreeClassifier(random_state=0),algorithm='SAMME.R',\n",
    "                                     n_estimators=200, learning_rate=0.5)\n",
    "\n",
    "#Actual Test Data to be submitted to Kaggle\n",
    "test_pred2 ,train_pred2=Stacking(model=ada_boost_model2,n_fold=10, train=X_train,test=df_Xte,y=Y_train)\n",
    "\n",
    "train_pred2=pd.DataFrame(train_pred2)\n",
    "\n",
    "test_pred2=pd.DataFrame(test_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosting Model 3\n",
    "#Use this KAGGLE Test dataset\n",
    "\n",
    "gradient_boost_model3 = GradientBoostingClassifier(n_estimators=500, learning_rate=0.5,\n",
    "     max_depth=4, max_leaf_nodes=15, random_state=0)\n",
    "\n",
    "print(\"Gradient Boosting  Kaggle Test Data training started\")\n",
    "starting_time = time.time()\n",
    "\n",
    "#Actual Test Data to be submitted to Kaggle\n",
    "test_pred3 ,train_pred3=Stacking(model=gradient_boost_model3,n_fold=10, train=X_train,test=df_Xte,y=Y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Gradient Boosting  Kaggle Test Data training finished, took {} seconds\".format(end_time - starting_time))\n",
    "\n",
    "train_pred3=pd.DataFrame(train_pred3)\n",
    "\n",
    "test_pred3=pd.DataFrame(test_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kaggle Test Data - Combining All 3 Models Random Forest, AdaBoost, Gradient Boosting STARTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_prediction = pd.concat([train_pred1, train_pred2,train_pred3], axis=1)\n",
    "test_prediction = pd.concat([test_pred1, test_pred2, test_pred3], axis=1)\n",
    "\n",
    "model = LogisticRegression(random_state=1)\n",
    "\n",
    "model.fit(validation_prediction,Y_train)\n",
    "\n",
    "#You we will not be able to score as this scoring is done by Kaggle; as we dont have y_validation / y_test \n",
    "\n",
    "# model.score(test_prediction, y_test)\n",
    "# model.score(test_prediction, Y_validation) # # We have to evaluate this in Kaggle as we dont have the df_Yte values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the individual Probabilities\n",
    "#This is what needs to be converted to txt for submission\n",
    "probs = model.predict_proba(test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute for Kaggle Test Data\n",
    "#Writing Probabilities to file\n",
    "\n",
    "SavetoTextFile('stacked_model',probs,df_Xte)\n",
    "\n",
    "# Create the data for submission by taking the P(Y=1) column from probs and just add a running index as the first column.\n",
    "# Y_sub = np.vstack([np.arange(Xte.shape[0]), probs[:, 1]]).T\n",
    "# Y_sub = np.vstack([np.arange(df_Xte.shape[0]), probs[:, 1]]).T  #For df_Xte\n",
    "\n",
    "# We specify the header (ID, Prob1) and also specify the comments as '' so the header won't be commented out with\n",
    "# the # sign.\n",
    "# np.savetxt('/content/shangyihuang/data/Y_sub_June_4_2020.txt', Y_sub, '%d, %.5f', header='ID,Prob1', comments='', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kaggle Test Data - Combining All 3 Models Random Forest, AdaBoost, Gradient Boosting ENDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking For Xte(Kaggle Submission) Data ENDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking ENDS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
